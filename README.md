# K-Nearest Neighbors (K-NN) Model

## Definition
> The K-Nearest Neighbors (K-NN) algorithm is a simple yet powerful machine learning algorithm used for both classification and regression tasks. It is a non-parametric and lazy learning algorithm that makes predictions based on the similarity between the data points.

## Key Characteristics
+ Non-Parametric:
_K-NN does not assume any underlying data distribution, making it flexible for various datasets._

+ Lazy Learning:
_The model does not build an explicit training model; instead, it memorizes the training data and performs computation during prediction._

## Pros and Cons
+ Pros
> 1. Simple and easy to implement.
> 2. Works well with smaller datasets and lower-dimensional data.
> 3. No training phase required.

+ Cons
> 1. Computationally expensive during prediction, especially with large datasets.
> 2. Sensitive to the choice of K and distance metric.
> 3. Performs poorly on high-dimensional data due to the "curse of dimensionality."

